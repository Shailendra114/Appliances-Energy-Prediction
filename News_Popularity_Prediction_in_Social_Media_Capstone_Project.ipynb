{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "News Popularity Prediction in Social Media - Capstone Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shailendra114/Appliances-Energy-Prediction/blob/main/News_Popularity_Prediction_in_Social_Media_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Predicting the news popularity in multiple social media platforms. </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn.The collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: Economy, Microsoft, Obama and Palestine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### IDLink (numeric): Unique identifier of news items\n",
        "* ### Title (string): Title of the news item according to the official media sources\n",
        "* ### Headline (string): Headline of the news item according to the official media sources\n",
        "* ### Source (string): Original news outlet that published the news item\n",
        "* ### Topic (string): Query topic used to obtain the items in the official media sources\n",
        "* ### PublishDate (timestamp): Date and time of the news items' publication\n",
        "* ### SentimentTitle (numeric): Sentiment score of the text in the news items' title\n",
        "* ### SentimentHeadline (numeric): Sentiment score of the text in the news items' headline\n",
        "* ### Facebook (numeric): Final value of the news items' popularity according to the social media source Facebook\n",
        "* ### GooglePlus (numeric): Final value of the news items' popularity according to the social media source Google+\n",
        "* ### LinkedIn (numeric): Final value of the news items' popularity according to the social media source LinkedIn\n",
        "\n",
        "\n",
        "### VARIABLES OF SOCIAL FEEDBACK DATA\n",
        "\n",
        "* ### IDLink (numeric): Unique identifier of news items\n",
        "* ### TS1 (numeric): Level of popularity in time slice 1 (0-20 minutes upon publication)\n",
        "* ### TS2 (numeric): Level of popularity in time slice 2 (20-40 minutes upon publication)\n",
        "* ### TS... (numeric): Level of popularity in time slice ...\n",
        "* ### TS144 (numeric): Final level of popularity after 2 days upon publication"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "u6Mj-B8gspCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the advancement in technology, news organizations have begun to rely more on online social platforms and media analytics as a way to attract readers. So, for news publishing sources, it’s become very important to know which kind of news articles will appeal more to the readers. In this project, firstly we have a news dataset which contains around 100000 news items published on three social media platforms: Facebook, Google Plus and LinkedIn, between November 2015 to July 2016 on four topics: Obama, Economy, Palestine, Microsoft. And we also have 12 social feedback dataset which contains the popularity level of news items in incremental time slices of 20 min after publication.\n",
        "\n",
        "As the first step of our experiment, we performed Data Cleaning by removing trash and duplicate data, applied null value treatment and removed outliers in the data set using the 90th percentile quantile method. We further applied the Standardization technique for feature scaling.\n",
        "\n",
        "In Exploratory Data Analysis, we categorized SentimentTitle, SentimentHeadline and sources to extract some meaningful insights from the data. Then we compared popularity between the social media platforms using multiple plots.\n",
        "\n",
        "We applied text-preprocessing techniques to transform the headline and title of the news items.\n",
        "\n",
        "For feature selection, we used ExtraTreeRegressor and Correlation matrix to obtain results on features.\n",
        "\n",
        "For model prediction, we used supervised machine learning algorithms like Decision Trees, Catboost, LightGBM, Gradient Boosting, KNN and then applied hyperparameter tuning techniques to obtain better accuracy and to avoid overfitting.\n",
        "\n",
        "So, without any further delay let’s move ahead!"
      ],
      "metadata": {
        "id": "lg2J4N8Usrqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U textblob\n",
        "!pip install catboost\n",
        "\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "3qa5q2vkteuQ",
        "outputId": "472a02f5-a451-43be-ce19-6b91dd0274a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Found existing installation: scikit-learn 1.0.2\n",
            "Uninstalling scikit-learn-1.0.2:\n",
            "  Successfully uninstalled scikit-learn-1.0.2\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.7)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "9Z5F19nrs7rQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ade9b23-149f-4274-be27-ba2b3b2a2ab2"
      },
      "source": [
        "# Lets import the important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualisation Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sklearn Libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "\n",
        "# Model Libraries\n",
        "import catboost as cb\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "# Miscellaneous Libraries\n",
        "from datetime import datetime\n",
        "import time\n",
        "import calendar\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import Word\n",
        "import shap\n",
        "import IPython\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets mount our drive------**"
      ],
      "metadata": {
        "id": "zcIlXSj2uPSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PIlPll7KueGj",
        "outputId": "0261da0a-5cd1-4a4a-b7c3-9f8315f0c133",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bqvZLU0ytIvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nB65h7kCufp7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}